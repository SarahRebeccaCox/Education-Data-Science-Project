---
title: "Survey Bias Among Video Gaming Redditors"
output: html_document
--- 

If you've ever taken a survey like the U.S. Census Survey, you know that they can be very long and difficult to answer completely honestly. In the case of the Census survey, this may be in part because the survey is very long and you have better things to do with your day than list every single item you've purchased in the last three months. <b>However, other surveys may probe you with questions that make you uncomfortable, or questions that you may alter your answer to depending who is asking. This is called social desirability response bias, and it may or may not be an issue for researchers relying heavily on survey data.</b>

Schneider and Buckley (2002) conducted a study evaluating school choice for parents in the Washington D.C. area. Survey results were compared to "revealed preferences" measured by online school search behavior. Findings included some differences in the importance of things like teacher quality between survey results and search behavior.

<b>This study aims to assess social desirability response bias among "Redditors" (users of the website reddit.com) who play video games or work in the video game industry.</b> Gamergate is the name given to the discussion and manifestation of sexism in video game culture, especially in the video game industry. A campaign of misogynist attacks targeted at specific female game developers and feminist culture critics was coordinated on the forums of Reddit, 4chan, and 8chan. Reddit users post on the forums with usernames, while 4chan and 8chan are completely anonymous. This made Reddit the best choice to use for this project.

Users in the population of interest were given a survey measuring two kinds of sexism, benevolent and hostile. Users had the option of providing their username in the survey. Then, text mining and sentiment analysis will be used to assess "sexist behavior" of users who gave their username via their previous posts on the website, and also to assess "general sexism" across the video gaming subreddit (under the assumption that survey respondents are a random sample of users on this subreddit).

```{r, echo=FALSE, warning=FALSE}

library(lattice)
library(knitr)
library(png)

```

```{r, echo=FALSE,message=FALSE,error=FALSE,warning=FALSE}
###LOAD DATA
average.scores <- read.csv("~/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles/AverageScores.csv")

average.scores <- average.scores[,-1]
setwd("~/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles/")
```

<img src="/Users/sarahcox/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles/SurveyScreen.png">

Within hours, Redditors were already starting to lash out: 

<img src="/Users/sarahcox/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles/Comments.png">

74 responses were gathered before the survey was closed. Of those:

21 identified as female, 50 as male, and 3 as something outside the binary,

7 work in the video game industry,

and 30 provided usernames.

The Ambivalent Sexism Inventory consists of 22 items and measures on Benevolent Sexism ("knight in shining armor" ideology, protects women who conform to traditional gender roles) and Hostile Sexism (negative feelings toward women). Each scale is scored from 0 to 5, where lower scores indicate lower levels of sexism as defined by the inventory.

```{r, echo=FALSE, fig.height=3}
###Overall scores
barchart(average.scores[15:16,2]~as.numeric(average.scores[15:16,3]),groups=average.scores[15:16,1],scales=list(x=list(rot=0,cex=0.8)),xlab="Scores",main="Sexism Scores Overall",auto.key=TRUE,xlim=c(0,5))

```

```{r, echo=FALSE, fig.height=3}
###By Gender
barchart(average.scores[1:6,2]~as.numeric(average.scores[1:6,3]),groups=average.scores[1:6,1],scales=list(x=list(rot=0,cex=0.8)),xlab="Scores",main="Sexism Scores by Gender",auto.key=TRUE,xlim=c(0,5))

```

```{r, echo=FALSE, fig.height=3}
###By Username Status
barchart(average.scores[7:10,2]~as.numeric(average.scores[7:10,3]),groups=average.scores[7:10,1],scales=list(x=list(rot=0,cex=0.8)),xlab="Scores",main="Sexism Scores by Username Status",auto.key=TRUE,xlim=c(0,5))
```

``````{r, echo=FALSE, fig.height=3}
###By Industry Status
barchart(average.scores[11:14,2]~as.numeric(average.scores[11:14,3]),groups=average.scores[11:14,1],scales=list(x=list(rot=0,cex=0.8)),xlab="Scores",main="Sexism Scores by Industry Status",auto.key=TRUE,xlim=c(0,5))
```

When you consider that the maximum score on each scale is 5 and the average scores for US respondents overall are closer to 2 and 3 (for women and men, respectively, according to the ASI website), this is actually not so bad! But let's take a look at the message boards:

A quick search of "girls" into the video games reddit subforum gives us this:

<img src="/Users/sarahcox/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles/RedditGirls.png">

Uh oh! Looks pretty bad. But how do I decide how bad? 

Reddit has a nice API:

<img src="/Users/sarahcox/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles/JSON.png">

Using this API, words and phrases can be extracted and ultimately analyzed to see if their sexism levels match up with the survey results. 

As a first look, let's scrape all the posts from each user who provided a username. You can access this information on the web by typing "http://www.reddit.com/user/USERNAME/comments/". Let's look at mine:
<img src="/Users/sarahcox/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles/MyRedditComments.png">

First, I'll set up the data and get the necessary libraries:

```{r}
### Get the list of usernames
responses <- read.csv("~/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles/CleanedResponses.csv")
username.field <- data.frame(responses[,4])
```
```{r,warning=FALSE,message=FALSE}
### Get necessary libraries
options(scipen=999)
library(lasso2)
library(tm)           # Framework for text mining.
library(SnowballC)    # Provides wordStem() for stemming.
library(qdap)         # Quantitative discourse analysis of transcripts.
library(qdapDictionaries)
library(dplyr)        # Data preparation and pipes %>%.
library(RJSONIO)
library(jsonlite)

```
```{r,echo=FALSE}
setwd("~/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/Usernames")
```

Next, I can create a list of usernames, and from that create a list of JSON URLs to extract text from:

```{r}

### Extract the list of non-blank usernames
n <- nrow(username.field)
username.list <- list()
for (i in 1:n) {
  username <- toString(username.field[i,])
	if (username != "") {
		username.list <- rbind(username.list,username)
	}
}

### Create list of URLs
n <- nrow(username.list)
url.list <- list()
for (i in 1:n) {
	url <- paste0("http://www.reddit.com/user/",username.list[i,],"/comments/.json")
	url.list <- rbind(url.list,url)
}

```

I'm only interested in user comments, so I'll create a data frame containing each user's comments:

```{r, warning=FALSE}
### The following code creates a data frame of user comments
url <- as.character(url.list[1])
rawdat <- fromJSON(readLines(url, warn = FALSE))
main.node <- rawdat$data$children$data$body

for (i in 2:n) {
  url <- as.character(url.list[i])
	rawdat <- fromJSON(readLines(url, warn = FALSE))
	main.2 <- rawdat$data$children$data$body
	main.node <- cbind(main.node,main.2)
}
colnames(main.node) <- username.list
```

Each column corresponds to a particular username. Now we have a really nice set of readable comments (take a look at comment number three!):


```{r}
head(main.node[,2])
```

My text-mining code works by importing text files, so I'll write each column of data into a text file.

```{r}
for (i in 1:n) {
  write(main.node[,i],file = as.character(username.list[i]))
}
```

Here are the text files, each named by username: 

```{r,echo=FALSE}
setwd("~/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles")
```

<img src="/Users/sarahcox/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles/TextFiles.png">

```{r,echo=FALSE}
setwd("~/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project//Usernames")
```

Now we can begin the actual text mining. The first step is to build the corpus, a body of documents to pull text from.

```{r}

#############
#TEXT MINING#
#############

### Build the corpus   


cname <- file.path("~/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/Usernames") #where files come from
cname
length(dir(cname))  #Number of documents
dir(cname)          #Check the filenames

docs <- Corpus(DirSource(cname))
docs #30 documents, it worked correctly
```

If we take a look at one of the documents, say Document 11, we see the following: 

```{r,echo=FALSE}
setwd("~/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles")
```

<img src="/Users/sarahcox/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/HTMLNeccessaryFiles/UnprocessedText3.png">

```{r,echo=FALSE}
setwd("~/Documents/Coursework/NYU - MS/Spring2015/Education DS/GitVersion/Education-Data-Science-Project/Usernames")
```

This text is readable, but not so easy to analyze.

We can use the following transformations to help clean this up:

```{r}
### Preprocessing
getTransformations()

#Replace @ and | with a space
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/|@|\\|")

# Replace "ampquot" with space
docs <- tm_map(docs, toSpace, "ampquot")

# Conversion to Lower Case
docs <- tm_map(docs, content_transformer(tolower))

# Remove Numbers
docs <- tm_map(docs, removeNumbers)

# Remove Punctuation
docs <- tm_map(docs, removePunctuation)

# Remove stop words  (ie for, very, and, of, are, ...)
docs <- tm_map(docs, removeWords, stopwords("english"))

# Remove Single Letters
docs <- tm_map(docs, removeWords, letters)

# Remove Whitespace
docs <- tm_map(docs, stripWhitespace)

# Stemming
docs <- tm_map(docs, stemDocument)

# Remove Single Letters
docs <- tm_map(docs, removeWords, letters)

# Remove Whitespace
docs <- tm_map(docs, stripWhitespace)
```

Finally, we can see what we have to work with: 

```{r}
inspect(docs[11])
```

This is usable data. Let's inspect it a little bit:

A document-term matrix is a matrix of term frequency in a collection of documents, where rows correspond to documents and columns correspond to terms. Let's create one:

```{r}
# Creating a Document Term Matrix
dtm <- DocumentTermMatrix(docs)
dim(dtm)

```

We can get the term frequencies by converting dtm into a matrix and summing column counts:
```{r}
freq <- colSums(as.matrix(dtm))
length(freq)
freq[100:105]
```

If we want to see the most frequent terms, we can order freq in reverse:

```{r}
ord <- order(freq)
freq[rev(ord)][1:20]
```

This isn't surprising or very interesting.

What might be more interesting is word associations. 

```{r}
findAssocs(dtm, "woman", corlimit=0.8)
findAssocs(dtm, "gender", corlimit=0.8)
findAssocs(dtm, "women", corlimit=0.8)
findAssocs(dtm, "girl", corlimit=0.8)
```

For quantitative analysis on these words, we can convert the term-document matrix into a matrix and retain only those words that are less than ten characters:


```{r}
words <- dtm %>%
  as.matrix %>%
  colnames %>%
  (function(x) x[nchar(x) < 10])
length(words)
typeof(words)
```

"words" is now a character vector of 3397 words. 

The closest to a sentiment analysis I was able to achieve utilizes a function in the library "qdap". The function, polarity(), outputs an average polarity score (polarity divided by number of words), the standard deviation, and a standardized polarity that is the average polarity divided by the standard deviation. 

```{r}
polarity(docs[1])
```

There is an argument within this function that allows for a custom polarity frame of terms and polarity weights, however I could not figure out what words or weights to use in a polarity frame for sexism or how to make it work with the function in time.

```{r}
qdapDictionaries::key.pol
```

The idea would be to create my own data frame composed of words from my own word set and scoring them based on sexism.

```{r}
head(words)
```


Future work:

Develop or find a measure of sexism to implement sentiment analysis with, preferably in context of words/sentences. 

Define a baseline sexism level for all reddit users.

Get a larger sample size, ideally with a more subtle sexism inventory with no subscores.

More efficient text-cleaning.

Find out if there's a way to extract all usernames of survey respondents, even those who chose to remain anonymous.